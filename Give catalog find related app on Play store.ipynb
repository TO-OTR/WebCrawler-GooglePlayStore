{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import requests        \n",
    "from bs4 import BeautifulSoup\n",
    "import xlwt\n",
    "import xlrd\n",
    "from xlutils.copy import copy\n",
    "import random\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter the url of catalog page \n",
    "# Capture the data of catalog page which contains a lot of apps\n",
    "def get_detail_page_url(url,headers):\n",
    "    strhtml=requests.get(url = url,headers = headers)#fack header and avoid website redirects\n",
    "    soup=BeautifulSoup(strhtml.text,'lxml')\n",
    "    data = soup.select('#fcxH9b>div.WpDbMd>c-wiz>div>div.N4FjMb>div>c-wiz>c-wiz>c-wiz>div>div.ZmHEEd>div>c-wiz>div>div>div.RZEgze>div>div>div.bQVA0c>div>div>div.b8cIId.ReQCgd.Q9MA7b>a')\n",
    "    # Establish the urls of every app' detail page\n",
    "    s='http://play.google.com'\n",
    "    url_all=[]\n",
    "    for item in data:\n",
    "        res = s+item.get('href')\n",
    "        url_all.append(res)\n",
    "    return url_all\n",
    "\n",
    "\n",
    "# Use the urls to visit every app's detail page to get info\n",
    "def get_detail(urlx,headers):   \n",
    "    url = urlx\n",
    "    strhtml = requests.get(url = url,headers = headers)#fack header and avoid website redirects\n",
    "    soup = BeautifulSoup(strhtml.text,'html.parser')\n",
    "    detail = []\n",
    "    #package \n",
    "    detail.append(url[45:]) # http://play.google.com/store/apps/details?id=\n",
    "    #name \n",
    "    detail.append(soup.find('h1',class_ = 'AHFaub').text) \n",
    "    #rank\n",
    "    detail.append(soup.find('div', role = 'img')['aria-label'])#obtain the value of attribute\n",
    "    #Ndownload\n",
    "    detail.append(soup.find_all('span',class_ = 'htlgb')[4].text) #too many class htlgb  ctrl+f search for span.htlgb and find it's 4th\n",
    "    #company\n",
    "    detail.append(soup.find('span',class_ = 'T32cc UAO9ie').text) #too many class htlgb ctrl+f search for span.htlgb and find it's 22th\n",
    "    #catalog\n",
    "    detail.append(soup.find('a', class_ = 'hrTbp R8zArc',itemprop = \"genre\").text) #ues itemprop,class,<a>to locate content\n",
    "    return detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid detection of googles, fake web crawler header and user agent\n",
    "def fack_headers():\n",
    "    ua=UserAgent()\n",
    "    headers={\n",
    "        'User-Agent':ua.random}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel creation and initial excel\n",
    "def create_excel(excel_name):\n",
    "    wb = xlwt.Workbook()\n",
    "    sh1 = wb.add_sheet('Info_Collection')\n",
    "    sh1.write(0,0,'package')\n",
    "    sh1.write(0,1,'name')\n",
    "    sh1.write(0,2,'rank')\n",
    "    sh1.write(0,3,'Ndownload')\n",
    "    sh1.write(0,4,'company')\n",
    "    sh1.write(0,5,'catalog')\n",
    "    wb.save(excel_name+'.xls')\n",
    "    \n",
    "\n",
    "# Input data\n",
    "def write(detail,i,excel_name):\n",
    "    rb = xlrd.open_workbook(excel_name)\n",
    "    r_sh = rb.sheet_by_name('Info_Collection')\n",
    "    wb = copy(rb)\n",
    "    sh1 = wb.get_sheet(0)\n",
    "    i += 1\n",
    "    sh1.write(i,0,detail[0])\n",
    "    sh1.write(i,1,detail[1])\n",
    "    sh1.write(i,2,detail[2])\n",
    "    sh1.write(i,3,detail[3])\n",
    "    sh1.write(i,4,detail[4])\n",
    "    sh1.write(i,5,detail[5])\n",
    "    wb.save(excel_name+'.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Entre the url of catalog!!! and the name of excel!!!\n",
    "    url='http://play.google.com/store/search?q=Children%20Monitor&c=apps&gl=FR'\n",
    "    excel_name = 'Monitor app and children app'\n",
    "    \n",
    "    # Create an excel to store data\n",
    "    create_excel(excel_name)\n",
    "    # Obtain the app's detail page \n",
    "    url_all = get_detail_page_url(url,fack_headers())\n",
    "    # loop to get detail of each app\n",
    "    detail=[]\n",
    "    for i in range (0,len(url_all)):\n",
    "        detail=[]\n",
    "        detail = get_detail(url_all[i],fack_headers())\n",
    "        write(detail,i,excel_name)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
